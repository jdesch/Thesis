%%--------------- Conclusion ------------------------------ 
\chapter{Conclusion}

This thesis has shown that is possible to use recent ideas from disciplines such
as biology, social science, psychology, and cognitive science to illuminate new
research areas within the artificial intelligence field.  Specifically, looking
at how humans learn, acquire memories, and solve problems provides a general
problem-solving framework.  This framework could lead to improvements in current
methods and a better understanding of artificial intelligence problems, while
increasing our understanding of the cognitive aspects of human problem solving.

One area that seemed like it could benefit from a human problem solving
framework is the word sense disambiguation problem from natural language
processing. Using the idea that human learning is tied to human memory, three
popular human memory models from cognitive science were presented; these models
were then unified and adapted into an algorithm.  An additional component from
psychology, the unconscious mind, was added to fill the need for bootstrapping
initial instances and adding a ``gut check'' to answers. The implementation of
the human memory model showed a modest improvement over a baseline algorithm,
and performed competitively against the top four programs from the Senseval 2
contest.  Analysis on the results had shown a number of inefficient areas within
the implementation, with a potential increase in accuracy of up to 25\%.

With the constraints of mimicking a biological model and having the system
perform competitively, a balance was necessary that would respectably showcase
both goals, thereby  opening alternate paths to better artificial intelligence
systems. Using human memory models, human-like learning and human psychological
constructs, an effective and novel approach to word sense disambiguation was
created.  While further research in each area could improve the generic human
intelligence framework, the application of this to other problems, and the
improvement of the accuracy of the technique, researchers must focus on what is
more important.  While quick gains can be found in improving the system's
accuracy, the potential for ground-breaking innovation stems from improving the
biological systems and adapting a general intelligence framework to more
problems, more inputs, and more data.

Researchers interested in word sense disambiguation and natural language
processing could find the graph theoretic algorithm for word proximity useful.
This algorithm, working in conjunction with a feedback-based edge-weighting
algorithm, should be adaptable to other problems.  With more research in the
meta-learning component, this adaptability could be automated and optimized to
the specific problem space.  Researchers interested in more realistic biological
modelling would find the method in which the differing algorithms connect
interesting. They also might be interested in the method used in pushing working
memory into long-term memory.  With the adaptation of text-based memory
constructs as a guide to memory creation, and the work of Ericsson and Kintsch
on memory components, the modification of the connective component to use more
than one ``sense'' would go a long way in creating a unified human-like memory
system.  Anyone interested in general artificial intelligence or meta-algorithmics would find the simple yet effective meta-learning system
interesting.  The results show both the success of the system in determining
correct rewards and punishments, and the negative impact an incorrect bias can
cause. Ultimately, using provably good meta-heuristics should to be able to
improve any artificial intelligence algorithm that requires rewards and
punishments.  Finally, researchers from cognitive science and psychology may be
interested in the interpretation of the various areas of the research used, as
adapting the system to perform well in one task in a computer program may
provide insight into some aspect of cognition.


\section{Future work}

As this was an initial foray into a novel approach to artificial intelligence,
memory, and learning, the results show a number of areas that would be
interesting candidates for further research.  If the goal of the researcher is
to get a feeling for the full-potential accuracy of the human memory model,
targeted work in the area of the meta-learning component, specifically the
decision making and weighting mechanism, would potentially be low-hanging fruit
for increasing accuracy.  Another area within accuracy optimization would be the
replacement of the static statistical learning algorithm with a more dynamic
algorithm; it is likely that there are algorithms with properties that would
better fit with the connective components algorithm. Finally, investigating how
graph-theoretical concepts could be applied to the connective component to
increase its accuracy or quicken its optimization time could lead to good
results.

The other option for a researcher is to improve the algorithm to better model
human memory. This could include separating the senses from the memory
components and handling the increased complexity that would come from this. The
majority of this work would be in logically organizing the sense information,
and allowing the components to interact within the problem space in working
memory and filter back to the long-term memory. A further step would be to
decouple the meta-learning component from the problem-solving algorithm,
allowing the optimizations and adjustments to occur at any time within a
problem, opening additional solution paths.  Another interesting angle would be
devising additional senses as inputs; this would include both how to simulate
new senses on the rather flat data sets, how to incorporate them into the system
(specifically how to store them in memory), and how to update the meta-learning
component to handle a new source of information.  Perhaps the most interesting
and difficult area would be to convert the meta-learning component to use
unsupervised learning techniques to find and exploit meta-parameters within the
system.  This would require an algorithm to learn what items within the system
can be parameterized and then through the hypothesis model, to test, compare,
and choose the best values to optimize the learning algorithms.
